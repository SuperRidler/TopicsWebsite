<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
    <head>
        <!--<title>Computing in Surgery</title>-->
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
        <meta name="description" content="Comouting in Surgery, Image Guidance." />
        <link rel="stylesheet" href="css/style_vertical.css" type="text/css" media="screen"/>
		<link rel="stylesheet" href="css/button.css" type="text/css"/>
    </head>
    <style>
        <!--
			a{
            color:#fff;
			font-family:Georgia;
			font-style:italic;
            text-decoration:none;
			}
			
        a:hover{
            text-decoration:none;
			cursor: pointer;
			}
			
        span.reference{
            position:fixed;
            left:10px;
            bottom:10px;
            font-size:13px;
            font-weight:bold;
			}
			
        span.reference a{
            color:#fff;
            text-shadow:1px 1px 1px #000;
            padding-right:20px;
			}
			
        span.reference a:hover{
            color:#ddd;
            text-decoration:none;
			}
		-->

    </style>
	<style type ="text/css">
		ts {line-height: 100%; font-size: 22px}
	</style>
    <body>
		<div id="top-floating-bar">
            <div id="bar-text"><ul class="nav">
				&nbsp;&nbsp;Computing in Surgery &nbsp;&nbsp;&nbsp;   
				<a onClick="goToPage(1);">Introduction</a>&nbsp;/&nbsp; 
                <a onClick="goToPage(2);">History</a>&nbsp;/&nbsp; 
				<a onClick="goToPage(3);">Image Registration</a>&nbsp;/&nbsp; 
                <a onClick="goToPage(17);">Augmented Reality</a>&nbsp;/&nbsp;
				<a onClick="goToPage(25);">Camera Calibration</a>
            </div></ul>
        </div>
		<div id="next-button">
			<a onClick="nextPage();" class="button">Next</a>
		</div>
		<div id="prev-button">
			<a onClick="prevPage();" class="button">Prev</a>
		</div>
        <div class="section black" id="section1">
            <h2>Computing in Surgery - Image Guidance</h2>
            <p>
                Write a nice intro to this topic <br />
				...or something.
            </p>
        </div>
        <div class="section white" id="section2">
            <h2>History</h2>
            <p>
                Pretty obvious we write some history.
            </p>
        </div>
		<!-- Image Registration  Starts Page 3 -->
		<div class="section black" id="section3">
            <h2>Image Registration</h2>
			<table width="90%" border="0" height="400"
				   style="position:absolute; left:47px">
				<tr>
					<td style="width:50%;">
						Comparing two images that need to be brought into the same spatial coordinates. <br />
						The process of mapping spatial coordinates of one image onto another. <br />
					</td>
					<td style="width:50%;text-align:center;">
						<img src="mimages/ir1.gif" alt="Image Registration Image"/>
					</td>
				</tr>
				<tr>
					<td style="width:50%;text-align:center;">
						<img src="mimages/ir2.jpg" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;vertical-align:top;">
						Two types of registration. <br />
						&nbsp;&nbsp;- Rigid registration               : Image translated, rotated or scaled. <br />
						&nbsp;&nbsp;- Non-rigid registration (Elastic) : Local-level deformation. E.g Regression or growth of disease.
					</td>
				</tr>
			</table>
        </div>
		<div class="section white" id="section4">
            <h2>Image Registration</h2>
            <table width="100%" border="0"
				   style="position:absolute; left:47px">
				<tr>
					<td style="width:50%;font-size:30px;">
						<h3> Rigid Registration</h3> <br />
						Intensity Based Rigid Registration <br />
						- Iteratively optimises 6 rigid-body parameters describing the orientation of the 3D data-set using a similarity measure. <br />
						Landmark Based Registration <br />
						- Selection of landmarks/feature points and matching them on the images helps to correctly register them. <br />
						Hybrid Registration <br />
						- Tries to incorporate the the benefits of both landmark based registration and intensity based rigid registration. <br />
					</td>
					<td style="width:50%;text-align:center">
						<img src="mimages/ir3.gif" alt="Image Registration Image"/>
					</td>
				</tr>
			</table>
        </div>
		<div class="section black" id="section5">
            <h2>Image Registration</h2>
			<table width="90%" border="0">
				<tr>
					<td style="width:50%;text-align:center">
						<h3>Non-Rigid Registration</h3>
						<img src="mimages/ir3.gif" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;">
						<br />Must use features in the image that are invariant to translation and rotation. 
						These feature points can then register the images using a method called landmark based registration method. <br />
						Average 4-Step Method: <br />
						1. Feature Detection <br />
						2. Feature Matching <br />
						3. Transform Model Estimation <br />
						4. Image Re-Sampling and Transformation <br />
					</td>
				</tr>
			</table>
        </div>
		<div class="section white" id="section6">
			<h2>Image Registration</h2>
			<table width="100%" border="0">
				<tr>
					<td style="width:50%;text-align:center;">
						<img src="mimages/ir4.jpg" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;">
						<h3>Feature Detection</h3> <br />
						Distinctive objects are manually or more preferably automatically detected in the images and can be represented by their point representatives. 
						These points are called control points.<br /> <br />
					</td>
				</tr>
			</table>
        </div>
        <div class="section black" id="section7">
            <h2>Image Registration</h2>
			<table width="100%" border="0"
				   style="position:absolute; left:47px">
				<tr>
					<td style="width:50%;">
						<h3>Feature Detection</h3> <br />
						In the past objects were manually selected by an expert. Two main approaches to automate this task.<br /> <br />
						Area-Based Methods - More emphasis on the feature matching step than on their detection. First step essentially omitted. <br />
						Feature-Based Methods - Significant regions, lines or points are understood as features here. 
					</td>
					<td style="width:50%;">
						<img src="mimages/ir5.jpg" alt="Image Registration Image"/>
					</td>
				</tr>
			</table>
        </div>
		<div class="section white" id="section8">
			 <h2>Image Registration</h2>
			<table width="100%" border="0"
				   style="position:absolute; left:47px">
				<tr>
					<td style="width:50%;font-size:30px;">
						<h3>Feature Based Methods</h3> <br />
						Features should be spread all over the image and be efficiently detectable in both images. 
						Expected to be stable and stay at fixed positions. 
						Comparability of feature sets is assured by the feature detector. 
						The number of common elements in the detected sets of features should be sufficiently high. 
						Feature-Based Methods do not work directly with image intensity values but represent information on a higher level. 
						This makes the method suitable for different kinds of imaging such as medical imaging.
					</td>
					<td style="width:50%;">
						<img src="mimages/ir6.png" alt="Image Registration Image"/>
					</td>
				</tr>
			</table>
        </div>
		<div class="section black" id="section9">
			<h2>Image Registration</h2>
			<table width="100%" border="0">
				<tr>
					<td style="width:50%;text-align:center;">
						<img src="mimages/ir7.png" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;">
						<h3>Types of Features</h3> <br />
						Region Features : High contrast closed-boundary regions of an appropriate size. <br /> <br />
						Line Features : Representations of general line segments. (Elongated anatomic structures in MI) <br /> <br />
						Point Features : The most distinctive points with respect to a specified measure of similarity. <br /> <br />
					</td>
				</tr>
			</table>
        </div>
		<div class="section white" id="section10">
			<h2>Image Registration</h2>
			<table width="100%" border="0"
				   style="position:absolute; left:47px">
				<tr>
					<td style="width:50%;vertical-align:top;">
						<h3>Types of Features</h3><br />
						Region Features detected by means of segmentation methods. 
						Dependent on the accuracy of the segmentation method. 
						Sub-pixel accuracy or registration can be achieved with iterative methods.
						Line Features expressed by pairs of line ends or middle points.
						Line detection can be done by standard edge detection methods like Canny detector or a detector based on the Laplacian of Gaussian. <br />
					</td>
					<td style="width:50%;text-align:center">
						<img src="mimages/ir7.png" alt="Image Registration Image"/>
					</td>
				</tr>
			</table>
        </div>
		<div class="section black" id="section11">
			<h2>Image Registration</h2>
			<table width="90%" border="0">
				<tr>
					<td style="width:50%;text-align:center">
						<img src="mimages/ir8.jpg" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;">
					<h3>Types of Features</h3> <br />
					Point Features detected in most cases by following the definition of a point as a line intersection, centroid of closed-boundary region or local maxima of the wavelet transform. 
					Defining corners is hard. Corner detection methods include SUSAN detector.
					Point Features include corners.  <br />
					Some registration techniques are using both area and feature based approaches.
					</td>
				</tr>
			</table>
        </div>
		<div class="section white" id="section12">
			<h2>Image Registration</h2>
			<table width="100%" border="0">
				<tr>
					<td style="width:50%;text-align:center;">
						<h3>Feature Matching</h3> <br />
						Matched by means of image intensity values in their close neighbourhoods, the feature spatial distribution, or the feature symbolic description.
					</td>
				</tr>
				<tr>
					<td style="text-align:center;">
						<br />
						<img src="mimages/ir9.jpg" alt="Image Registration Image"/>
					</td>
				</tr>
			</table>
        </div>
		<div class="section black" id="section13">
			<h2>Image Registration</h2>
			<table width="100%" border="0">
				<tr>
					<td style="width:50%;text-align:center;">
						<br />
						<img src="mimages/ir10.jpg" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;">
					<h3>Feature Matching</h3> <br />
					Area-Based Methods - Suits the registration of images which locally differ only by a translation. <br /> <br />
					Any images deformed by more complex transformations will not register properly. <br /><br />
					Another disadvantage is that there is a high chance that any two non-detailed areas will be matched incorrectly. 
					</td>
				</tr>
			</table>
        </div>
		<div class="section white" id="section14">
			<h2>Image Registration</h2>
			<table width="100%" border="0"
				   style="position:absolute; left:47px">
				<tr>
					<td style="width:50%;">
						<h3>Feature Matching</h3> <br />
						<br />
						Correlation-Like Methods - Classic area-based methods including cross-correlation try to matching image intensities without structural analysis. <br /> <br />
						This makes it very sensitive to intensity changes such as noise.
					</td>
					<td style="width:50%;text-align:center;">
						<br />
						<img src="mimages/ir11.png" alt="Image Registration Image"/>
					</td>
				</tr>
			</table>
        </div>
		<div class="section black" id="section15">
			<h2>Image Registration</h2>
			<table width="90%" border="0">
				<tr>
					<td style="width:50%;text-align:center;">
						<br />
						<img src="mimages/ir12.jpg" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;font-size:30px;">
						<h3>Feature Matching</h3> <br />
						Fourier Methods - Preferred when there is varying conditions (varying light intensity) or the images are corrupted with noise. 
						Phase correlation method is based on the Fourier Shift Theorem. <br />
						This computes the cross-power spectrum of the images and looks for the location of the peak in its inverse. <br />
						This method has robustness against noise and illumination levels. <br />
						Time savings are more significant as the image size increases. 
						In case of varying image scales, combine polar-log mapping and phase correlation.
					</td>
				</tr>
			</table>
        </div>
		<div class="section white" id="section16">
			<h2>Image Registration</h2>
			<table width="90%" border="0"
				   style="position:absolute; left:47px">
				<tr>
					<td style="width:50%;">
						<h3>Feature Matching</h3>
						<ts>Mutual Information Methods - Leading technique in multi modal registration. Required for medical imaging. 
						Comparison of anatomical and functional images of the patients body can lead to a a diagnosis that would be impossible to gain otherwise. 
						Remote sensing allows for the exploitation of other sensor types too.</ts>
					</td>
					<td style="width:50%;text-align:center;">
						<img src="mimages/ir13.jpg" alt="Image Registration Image"/>
					</td>
				</tr>
				<tr>
					<td style="width:50%;text-align:center;">
						<img src="mimages/ir14.png" alt="Image Registration Image"/>
					</td>
					<td style="width:50%;font-size:22px;">
						Originates in information theory, measures statistical dependency between two data sets and is particularly suitable for different modalities. <br />
						This method is based upon the maximum of MI. Can be sped up by using the coarse-to-fine resolution strategy (the pyramidal approach). <br />
						Can be used to match MRI images and 3D object model matching to the real scene. Gradient Descent Optimisation. 
					</td>
				</tr>
			</table>
        </div>
		<div class="section black" id="section17">
			<h2>Augmented Reality</h2>
			
			<table width="90%"
				   style="border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td>
					With the increased use of robotic assisted, minimally invasive, surgery this has become the ideal environdment for such things as Augmented Reality. <br />
					Traditional AR methods, however, such as overlaid AR, have suffered from a lack of depth perception. <br />
					Even when the objects in question are rendered at the correct depth, the brain perceives the virtual images to be floating, thus hampering the process.
				</td>
				
				<td>
					<img src="augimages/gr4-manualnavigation.jpg" alt="Manual Navigation Image"/>
				</td>
			</tr>
			</table>
        </div>
		<div class="section white" id="section18">
			<h2>Augmented Reality</h2>			
			<table width="100%"
				   style="border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td>
					To perceive the image as embedded the brain expects some form of occlusion/obstruction.<br />
					As such AR allowed the surgeon to view the medical imagery from a natural viewpoint <br />
					<br />
					&nbsp;&nbsp;&nbsp;&nbsp;<b>Positives</b>;<br />
					 ~ The effectiveness and clinical benefit of AR has been widely recognised
					</td>
			</tr>
			<tr></tr><tr></tr><tr></tr>
			<tr>
				<td>
				&nbsp;&nbsp;&nbsp;&nbsp;<b>Negatives</b>;<br />
					 ~ The application of the technique to cardiothoracic<br /> 
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or gastrointestinal surgery remains limited<br />
					 ~ Tissue deformation can present significant challenge to AR displays<br />
				</td>
			</tr>
			</table>
        </div>
		<div class="section black" id="section19">
			<h2>Augmented Reality</h2>
			<table width="90%"
				   style="border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td>
				Techniques such as P-Q Space Rendering provide see-through vision of embedded virtual objects.
				These maintain the projected anatomical detail of the eposed surface whilst aiding the surgery.
				</td>
			</tr>
			</table>
        </div>
		<div class="section white" id="section20">
			<h2>Augmented Reality</h2>
			<table width="90%"
				   style="border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td>
				The idea of P-Q Space Rendering is to render the exposed surface as a translucent layer whilst ensuring that sufficient detail remains to aid both navigation and depth cue-ing. <br />
				The surface geometry is based on p-q space representation. 'p' and 'q' represent the slope of the surface along the x and y axes, respectively.
				</td>
				<td width="50%"></td>
			</tr>
			</table>
        </div>
		<div class="section black" id="section21">
			<h2>Augmented Reality</h2>
			<table width="90%"
				   style="border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td style="font-size:28px" colspan="2">
				During broncoscopic and endoscopic procedures, P-Q Space is used heavily alongside the Shape from Shading Algorithm. 
				This is a classical problem within the field of computer vision. 
				It addresses the issue of extracting both surface and relative depth information from a single image.
				</td>
			</tr>
			<tr>
				<td style="font-size:20px" colspan="2"><br /></td>
			</tr>
			<tr>
				<td style="font-size:20px" colspan="2">
					Below is an example of shape from shading used to pull the depth information of the left image.<br />
					The results have been mathematically protrayed as a graph.
				</td>
			</tr>
			<tr>
				<td colspan="2">
					<img src="augimages/pradosFaceAndReconstruction.jpg" alt="Shape From Shading"/>
				</td>
			</tr>
			<tr>
			<td style="width:25%"></td>
				<td style = "font-size:10px">
					image curtosy of; http://hal.inria.fr/inria-00394230/en/
				</td>
			</tr>
			</table>
        </div>
		<div class = "section white" id = "section22">
			<h2>Augmented Reality</h2>
			<table width="90%"
				   style = "border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td>
					<img src = "augimages/equation.jpg" alt = "equation"/>
				</td>				
			</tr>
			<tr>
				<td style = "font-size:28px">
					<b>E(x,y)</b> represents the image irradiance, the amount of light falling on a surface<br />
					<b>L</b> is reflected radiance of the light-source, the amount of light radiated from a surface<br />
					<b>d</b> is the lens diametre<br />
					<b>f</b> is the focal length<br />
					<b>α</b> is the angle between the optical axis and the light ray going through the centre of the observed angle
				</td>
			</tr>
			</table>
        </div>
		<div class="section black" id="section23">
			<h2>Augmented Reality</h2>
			<table width="90%"
				   style="border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td style="font-size: 25px">
					Given the previous equation, α is assumed negliable. However when using endoscopes this cannot be assumed as the camera and light source are assumed to be near the surface.
					As such, the image irradiance in this situation can be described by a constant of the camera parametres, multipled by the surface albedo, the angle between the incident ray and surface normal and a monotomically decreasing function of the surface point and light source.
				</td>
				<td width="50%"></td>
			</tr>
			<tr>
				<td style="font-size: 25px">
					<br />
					When using p-q space rendering the surfaces normals for each pixel are extracted (using linear local shape-from-shading algorithms derived from the necessary camera and lighting constraints). 
					Given a 3D tomographic model, the p-q components are then extracted.
				</td>
				<td width="50%"></td>
			</tr>
			</table>
        </div>
		<div class="section white" id="section24">
			<h2>Augmented Reality</h2>
			<table width="90%"
				   style="border:0px solid white;
						  position:absolute; left:47px">
			<tr>
				<td>
					In P-Q Space representation, the angle between the normal vectors both before and after rigid body registration will remain the same for every surface point.
					This means that local deformation is identified where the angle diverts from the overall mean of the 3D model.
				</td>
				<td width="50%"></td>
			</tr>
			</table>
        </div>
		

		<div class="section black" id="section25">
			<h2>Camera Calibration</h2>
			<table width="100%" border="0">
				<tr>
					<td style="width:55%;text-align:left;vertical-align:top;">
						<h3 style="font-size:30px;">What is camera calibration?</h3> 
						<p style="width:90%;font-size:22px;">Basically, the process of determining the external(position,orientation) and internal(focal length, image center, scaling factors, lens distortion etc.) parameters of a camera.<br/> <br/>
										This is required for creating a mapping between 3-dimensional coordinates(the real world) and 2-dimensional coordinates (the projective plane).<br/><br/> 
										As it might turn out later, this is potentially <u>VERY</u> useful.
						</p> <br/>
						<h3 style="font-size:26px;">Uses:</h3>
						<p style="width:90%;font-size:22px;"> - surgery : more exactly, <u>surgical tracking</u>; <br/>
									    - computer vision - e.g. efficient algorithms for calculating changes in perspective in a virtual 3D space (e.g. video games, AR), or more advanced applications in robotics, such as hand-eye coordination; <br/>
									    - 3D reconstruction (that is i.e. finding structural properties of 3D objects, such as outer shape, by using the information got out of their projections on a plane - 2D images, to be precise); <br/>
						</p>
					</td>
					<td style="width:45%;font-size:15px;text-align:center;vertical-align:top;">
						<br/>
						<img src="ccimages/cc1.jpg" alt="Camera Calibration: failed import;"/> <br/>
						Copyright:  <a href=http://www.cse.unr.edu/~aerol/projecthome/> http://www.cse.unr.edu/~aerol/projecthome/</a>  .
					</td>
				</tr>
			</table>
        </div>
		

		<div class="section white" id="section26">
			<h2>Camera Calibration</h2>
			<table width="100%" border="0">
				<tr style="vertical-align:top;">
					<td style="width:40%;font-size:15px;">
						<br/> 
						<img src="ccimages/cc2.png" alt="Camera Calibration: failed import;"/> <br/>.
					</td>
					<td style="width:60%;font-size:22px;">
						<h3 style="font-size:30px;text-align:center;">How does it work?</h3> <br/>
						<p style="width:90%;text-align:justify;">There are several algorithms to choose from, each with its own benefits and drawbacks. However, most of them fit into one of two categories:<br/><br/>
						 - Linear methods : all of the equations used to derive the parameters, or conversely, to obtain the coordinates of the 3D object (the so-called ‘feature’) are linear.It doesn’t take into account errors created by lens distortion or alignment => equations are computationally simpler. Hall and Faugeras-Toscani methods emphasize on this approach; <br/><br/>
						 - Non-linear methods : equations involve non-linear terms (required for modelling any sort of distortion/scaling effects), resulting in a more complex computation. Zhang’s and Tsai’s work on this sort of algorithms are “influential”. The other major drawback: need for a good initial "guess" of the parameters;<br/><br/>
					</p>
					</td>					
				</tr>	
			</table>
			<p style="font-size:22px;width:80%;text-align:left;">One smart approach was to use a combination of both methods in order to reduce the number of necessary takes on the algorithm (can go as high as 5 times more measurements than unknowns), without significant loss in accuracy.
			</p><br/>
        </div>
		

		<div class="section black" id="section27">
						<h2>Camera Calibration</h2>
			<table width="100%" border="0">
				<tr style="vertical-align:top">
					<td style="width:50%;font-size:22px;">
						<h3 style="font-size:30px;text-align:left;">How does it work?</h3> <br/><br/>
						<h3 style="font-size:26px;text-align:left;">Some food for thought: </h3>
						<p style="width:90%;text-align:left;"> -How do you construct an accurate, reliable model of the typical situation?<br/>
										       -How should the camera be mathematically modelled? <br/>
										       -Finally, how do you actually put the algorithms in practice? 
						</p>
					</td> 
					<td style="width:50%;text-align:center;font-size:15px;"><br/>
						<img src="ccimages/cc4.png"/><br/>
						Copyright: <a href=http://en.wikipedia.org/wiki/Pinhole_camera> http://en.wikipedia.org/wiki/Pinhole_camera </a>
					</td>
				</tr>
				<tr>
					<td style="text-align:center;font-size:15px;" >
						<img src="ccimages/cc42.png" alt="Camera Calibration: failed import;"/>
					</td>
					<td style="text-align:left;font-size:22px;">
					<p style="width:90%;"> We can start off with a very simple camera model- the “ideal pinhole camera”.<br/>
							       Mainly, we assume that the camera aperture is infinitely small, so that each point in space has only one projective line going through itself and its image (namely, the line that goes through the point and the aperture).<br/>
    							       There is a mapping between each point in space and the projective plane(the image) - assuming, of course, that we refer both points in the same system of coordinates; at its simplest, a feature can be represented by a point in space.
					</p>
					</td>
					
				</tr>
			</table>	
        </div>
		
		
		<div class="section white" id="section28">
			<h2>Camera Calibration</h2>
			<h3 style="text-align:left;font-size:30px;"> New way of seeing things! </h3>
			<p style="width:90%;text-align:left;font-size:22px;">Finally, while the equations for this model could be modeled in an Euclidean geometry, we might  (I insist) use an alternative solution, quite  fit for our purpose : <u>homogeneous coordinates</u> and <u>projective geometry</u>.<br/><br/>

    									     Things work somewhat like this:<br/><br/>
									     - if you represent a point (x, y) in the plane, its homogeneous coordinates are of the form  (xZ, yZ, Z), where Z is a randomly chosen real number (mainly, the set of all values that preserve this [xZ:yZ:Z] ratio <u>forms an equivalence class</u> in 3D space! ); you recover your original coordinates by setting Z to 1 - quite expected;<br/>
    									     - alternatively, a point caractherised by 3 (or ,more generally, n ) dimensions in Euclidean Space is caractherised by 4 (n+1, respectively) homogeneous coordinates, which preserve the initial ratio in the Euclidean Space (e.g. : [x1 :x2 : … : xn : 1] );<br/><br/>
									     Why does this simplify things in our problem? several reasons:<br/>
        								     - imagine that the new coordinate in the homogeneous system (in the case of the 2D point (x,y)) was actually a coordinate in 3D space, according to the 3rd axis.<br/>      What would points in the same equivalence class represent?<br/>What set would the set of points with fixed 3rd coordinates represent?</br>
        								     - translation is easier representable as a square matrix ; for example, translation of points (x,y) to points (x+t1,y1+t2), with t1 t2 fixed constants, would be modelled by the equation:
				<div style="text-align:center"><img src="ccimages/translationmat.png" alt="Camera Calibration: failed import;" align="center"/></div>
			</p>
        </div>
		

		<div class="section black" id="section29">
			<h2>Camera Calibration</h2>
			<h3 style="text-align:left;font-size:30px;"> New way of seeing things! </h3>
			<p style ="width:90%;font-size:22px;"> - this also means that we can model changes of coordinate system (mainly, a rotation and a translation) by product of matrices; <br/>
							       - moreover, it’s possible to map points at infinity; there is one point (actually, an equivalence class) for each particular direction; one of the consequences is that you can solve equations involving parallel lines much more naturally;<br/>
			</p><br/>
			<div style="text-align:center;">
					<img src="ccimages/thumbsup.jpeg" alt="Camera Calibration: failed import;"/>
					<p style="width:100%;font-size:30px;">We're set!</p>
			</div>
        </div>
		

		<div class="section white" id="section30">
			<h2>Camera Calibration</h2>
			<table width="100%" border="0">
				<tr style="vertical-align:top;font-size:22px;">
					<td style="width:50%;text-align:left;">
						<h3 style="font-size:30px;">What to do?</h3>
						<p style="width:80%;"> Well, whatever our purpose is, we can’t really do anything without finding that camera (or projection) matrix!</br>
   						    - Acting as a mapping between 3D homogeneous coordinates (4-by-1 matrices) and 2D homogeneous coordinates (3-by-1 matrices), our matrix will probably be 3-by-4:<br/><br/>
						    Believe it or not, this is the general equation.
						</p>				
					</td>
					<td style="width:50%;text-align:center;"><br/><br/><br/>
						<img src="ccimages/generalmateq.gif" alt="Camera Calibration: failed import;"/>
					</td>
				</tr>
			</table>
			<div style="width:100%;font-size:22px;text-align:left;">
				<p style="width:90%;">-Of course, the parameters depend on all possible factors that can influence the mapping of 3D features to the image (potentially very many);</br>

						      -In our simple pinhole camera model we assume just some of these factors to be part of our matrix, and we’ll set some others later on;<br/><br/>

						      -<u>External parameters</u>: <u>position</u> of the camera relative to the original system of the projected object; <u>orientation</u> of the camera relative to ... (it will very rarely be the case that the camera’s coordinate system is aligned with that of the object);<br/><br/>

-<u>Internal parameters</u>:

        					      -<u>scaling factor</u> (width-height ratio for pixels); <u>focal length</u> (this one is responsible for any sense of perspective in your image, and would be really difficult to model in its natural form);<br/>

						      -we’ll avoid in-depth modelling of focal length or distortion in the linear model; keep in mind though that because of our simplifications, higher errors are prone to occur; 
				</p> 
			</div>
        </div>
		
		<div class="section black" id="section31">
			<h2>Camera calibration</h2>
			<table width="100%" border="0">
				<tr style="vertical-align:top;">
					<td colspan="2"style="width:40%;font-size:15px;text-align:center;"><br/><br/>
						<img src="ccimages/eq1a.gif" alt="Camera Calibration: failed import;"/><br/><br/>
						<img src="ccimages/eq1b.gif" alt="Camera Calibration: failed import;"/><br/>
					</td>
					<td style="width:60%;font-size:22px;">
						<h3 style="font-size:30px;text-align:center;">Determining the camera matrix</h3> <br/>
						<p style="width:90%;text-align:left;">
							The mathematics is not too complicated - assuming you know how to work with matrices.<br/><br/>

							Assuming you had a feature at [x,y,z,1] in the camera’s system (typically you use a checkerboard-like grid called "Tsai grid" to find out the coordinates easily), and that the image plane was at distance f (focal length) from the camera, on the z-axis, one could work out the coodinates of the image point by triangle similarity (equations on left).
						</p>
					</td>
				</tr>
				<tr>
					<td style="width:20%;font-size:15px;text-align:center;"><br/>
						<img src="ccimages/ccenter.png" alt="Camera Calibration: failed import;"/><br/>
						Copyright: <a href=http://www.umiacs.umd.edu/~ramani/cmsc828d/lecture9.pdf> http://www.umiacs.umd.edu/~ramani/cmsc828d/lecture9.pdf </a>
					</td>
					<td style ="text-align:center;">
						<img src="ccimages/pixeq.gif" alt="Camera Calibration: failed import;"/><br/>						
						<img src="ccimages/Kmateq.gif" alt="Camera Calibration: failed import;"/><br/>
						<img src="ccimages/alphaeq.gif" alt="Camera Calibration: failed import;"/></br>
					</td>
					<td style="width:60%;font-size:22px;">
						<p style="width:90%;font-size:22px;text-align:left;">
							This, combined with information regarding the image center and pixel size, yields us a new result.<br/><br/>
							(x0,y0) represents the image center, and kx and ky are scaling factors for pixels. <br/><br/>
							The 3x4 K matrix (on the left) is your most basic calibration matrix.
						</p>
					
					</td>
				</tr>
			</table>
        </div>
		

		<div class="section white" id="section32">
			<h2>Camera calibration</h2>
			<table width="100%" border ="0">
				<tr style="vertical-align:top;">
					<td style="width:60%;font-size:22px;text-align:left;">
						<h3 style="font-size:30px;text-align:left;">Determining the camera matrix</h3> 
						<p style="width:90%">Unfortunately, it is very rare that the coordinate system of the target is aligned to that of the camera. We must first perform two transformations, mainly a rotation and a translation. <br/><br/>
								     It turns out the matrix that describes this transformation looks something like this:<br/><br/>
								     Therefore, we can multiply the two matrices to obtain our real camera matrix:<br/></br>
								     This projection matrix P has around 11 variable parameters : 5 from K, 3 from R and 3 from the translation vector. There are quite a lot of unknowns!  <br/> 

								     Cool, this is how it looks in theory, but how do we determine it in practice? <br/><br/>
								     We use certain points we know about, we project them through the camera we have, and we use the info on the image points to write these equations:<br/><br/>
								     Since each pair of real point-image point give us two equations, it would be expected that 6 points be enough to find our parameters. However, due to the possibility of high errors, it is recommended that more points be used. This is called the Direct Linear Method.
						</p>
					</td>
					<td style="width:40%;font-size:15px;text-align:center;"><br/><br/><br/>
						<img src="ccimages/RTmat.gif" alt="Camera Calibration: failed import;"><br/></br></br>
						<img src="ccimages/finalmat.gif" alt="Camera Calibration: failed import;"/><br/></br><br/><br/>
						<img src="ccimages/detmat1.gif" alt="Camera Calibration: failed import;"/><br/>
						Copyright: <a href=http://www.peterhillman.org.uk> http://www.peterhillman.org.uk </a>
					</td>
				</tr>
			</table>
        </div>
		<div class="section black" id="section33">
			<h2>Camera calibration</h2>
			<h3 style="font-size:30px;text-align:center;">Is this it?</h3> <br/>			
			<p style="width:90%;font-size:22px;text-align:left;">
				Well, nothing should stop you from implementing all this on your computer and start your career as a video game designer.<br/>
			</p><br/>
			<h3 style="font-size:26px;text-align:left;">Anything else to it?</h3>
			<p style="width:95%;font-size:22px;text-align:left;float:right;">
				Definitely.<br/>
					<img src="ccimages/endoscope.jpg"align="right"/></br>
				Uses for camera calibration range widely, from calibrating your personal camera, to modelling computer vision, to surgery, especially surgical tracking.</br>
				- embedded light cameras for tracking position of different instruments, relative to different markers; <br/>
    				- small cameras made for endoscopic interventions (calibration must be much more precise), resulting in an efficient and non-invasive way of doing some types of surgery; <br/>
				
				- X-ray cameras (Selby's method);<br/>
    				- possibly 3D reconstruction of surfaces; <br/><br/>
				Many of these application might need an algorithm with a higher precision than the Direct Linear Method. For more info, Tsai's and Zhang's writings provide some non-linear methods for more specific needs. Also there's a large literature on the subject, even on the Internet. Check it out!
			</p>
        </div>
		<div class="section white" id="section34">
			<div class="section white" id="section26">
			<h2>Camera calibration</h2>
			<h3 style="font-size:30px;text-align:left;">Just for the curious</h3> <br/>
			<p style="width:90%;font-size:22px;text-align:left;">
				If the last one got your attention, the main algorithm for 3D recovery is quite easy: once you have two cameras (with known projection matrices P1, P2) which observe the same point, you have to solve the equations: <br/>
					<img src="ccimages/rec3d.gif" alt="Camera Calibration: failed import;"/></br>
				In something more visual, this translates to finding the intersection of two projective lines [image - epipolar geometry]:</br></br>
				<div style="text-align:center;font-size:15px"> 				
					<img src="ccimages/2cam3d.jpg" alt="Camera Calibration: failed import;"/></br>
				</div>
			</p>

        </div>
		<div class="section black" id="section35">
			<h2>Testing Purposes - Page 11</h2>
			<p>
				For testing.
			</p>
        </div>
		<div class="section white" id="section36">
			<h2>Testing Purposes - Page 11</h2>
			<p>
				For testing.
			</p>
        </div>

        <!-- The JavaScript -->
        <!--<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js"></script>	-->
		<script type="text/javascript" src="js/jquery.min.js"></script>		
        <script type="text/javascript" src="js/jquery.easing.1.3.js"></script>
        <script type="text/javascript">
		page=1;
		lastPage=34;
		mydiv = document.getElementById('prev-button');
		mydiv.style.visibility = "hidden";
		browserThing();
		onipad = false;
			function goToPage(toPage){
				page = toPage;
				$('html, body').stop().animate({
						scrollTop: $("#section"+page).offset().top}, 1500,'easeInOutExpo');
					if(page==1){
					mydiv = document.getElementById('prev-button');
					mydiv.style.visibility = "hidden";
					mydiv = document.getElementById('next-button');
					mydiv.style.visibility = "visible";
					}else
					if(page==lastPage){
						mydiv = document.getElementById('prev-button');
						mydiv.style.visibility = "visible";
						mydiv = document.getElementById('next-button');
						mydiv.style.visibility = "hidden";
					}else{
						mydiv = document.getElementById('prev-button');
						mydiv.style.visibility = "visible";
						mydiv = document.getElementById('next-button');
						mydiv.style.visibility = "visible";
					}
			}
			function nextPage(){
				if(page!=lastPage){
					page++;
					$('html, body').stop().animate({
						scrollTop: $("#section"+page).offset().top
                    }, 1500,'easeInOutExpo');
				}
				if(page==2){
					mydiv = document.getElementById('prev-button');
					mydiv.style.visibility = "visible"; 
				}else 
				if(page==lastPage){
					mydiv = document.getElementById('next-button');
					mydiv.style.visibility = "hidden";
				}
			}
			function prevPage(){
				if(page!=1){
					page--;
					$('html, body').stop().animate({
						scrollTop: $("#section"+page).offset().top
                    }, 1500,'easeInOutExpo');
				}
				if(page==1){
					mydiv = document.getElementById('prev-button');
					mydiv.style.visibility = "hidden";
				}
				if(page!=lastPage){
					mydiv = document.getElementById('next-button');
					mydiv.style.visibility = "visible";
				}
			}
			function browserThing(){
				if(navigator.platform=='iPad'){
					alert('Sorry! - Not ready for iPad.');
					/*document.getElementById('next-button').style.display='none';
					document.getElementById('prev-button').style.display='none';
					onipad = true;
					var introNext = document.getElementById('intro-next-button');
					introNext.style.position="relative";
					introNext.style.left="825px";
					introNext.style.top="275px";
					introNext.style.visibility="visible";*/
				}
			}
        </script>
    </body>
</html>
